{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0784d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070a06a",
   "metadata": {},
   "source": [
    "# Coding multiple layers of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6373babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "inputs_to_layer1 = [[1, 2, 3, 2.5],\n",
    "                    [2., 5., -1., 2],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "layer1_neuron_weights = [[0.2, 0.8, -0.5, 1],\n",
    "                         [0.5, -0.91, 0.26, -0.5],\n",
    "                         [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases_of_layer1_neurons = [2, 3, 0.5]\n",
    "\n",
    "layer2_neuron_weights = [[0.1, -0.14, 0.5],\n",
    "                         [-0.5, 0.12, -0.33],\n",
    "                         [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases_of_layer2_neurons = [-1, 2, -0.5]\n",
    "\n",
    "# Outputs of layer 1 which will get a batch inputs which will be feed as an input to the next layer\n",
    "layer1_ouputs = np.dot(inputs_to_layer1, np.array(layer1_neuron_weights).T) + biases_of_layer1_neurons\n",
    "\n",
    "# Final Output of the neural network having 2 layers\n",
    "layer2_outputs = np.dot(layer1_ouputs, np.array(layer2_neuron_weights).T) + biases_of_layer2_neurons\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff0d69",
   "metadata": {},
   "source": [
    "# Coding a neural netowork of 5 layers where each layer has 1-10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2beb9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the final layer having 3 neurons:  [[101.86183461  72.67893501 -43.42866754]\n",
      " [  4.06330904 -12.84601415 -11.1800319 ]\n",
      " [ 46.6106128   35.98991001 -20.32862086]]\n",
      "\n",
      "Batch wise outputs -->\n",
      "Batch 1 output: [101.86183461  72.67893501 -43.42866754]\n",
      "Batch 2 output: [  4.06330904 -12.84601415 -11.1800319 ]\n",
      "Batch 3 output: [ 46.6106128   35.98991001 -20.32862086]\n"
     ]
    }
   ],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "inputs_to_layer1 = np.array([\n",
    "    [1.2, -0.7, 3.1, 0.5, 2.3],\n",
    "    [2.1, 0.9, -1.5, 2.7, -3.2],\n",
    "    [0.0, -1.2, 1.5, 1.1, 0.9]\n",
    "])\n",
    "\n",
    "# Number of features from input\n",
    "input_size = inputs_to_layer1.shape[1]\n",
    "\n",
    "# Layer 1 (6 neurons)\n",
    "layer1_neuron_weights = np.random.randn(6, input_size).tolist()\n",
    "biases_of_layer1_neurons = np.random.randn(6).tolist()\n",
    "\n",
    "# Layer 2 (4 neurons)\n",
    "layer2_neuron_weights = np.random.randn(4, 6).tolist()\n",
    "biases_of_layer2_neurons = np.random.randn(4).tolist()\n",
    "\n",
    "# Layer 3 (8 neurons)\n",
    "layer3_neuron_weights = np.random.randn(8, 4).tolist()\n",
    "biases_of_layer3_neurons = np.random.randn(8).tolist()\n",
    "\n",
    "# Layer 4 (5 neurons)\n",
    "layer4_neuron_weights = np.random.randn(5, 8).tolist()\n",
    "biases_of_layer4_neurons = np.random.randn(5).tolist()\n",
    "\n",
    "# Layer 5 (output layer with 3 neurons)\n",
    "layer5_neuron_weights = np.random.randn(3, 5).tolist()\n",
    "biases_of_layer5_neurons = np.random.randn(3).tolist()\n",
    "\n",
    "# Outputs of Layer 1 which will be fed as the input to layer 2\n",
    "layer1_outputs = np.dot(inputs_to_layer1, np.array(layer1_neuron_weights).T) + biases_of_layer1_neurons\n",
    "\n",
    "# Outputs of Layer 2 which will be fed as the input to layer 3\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(layer2_neuron_weights).T) + biases_of_layer2_neurons\n",
    "\n",
    "# Outputs of Layer 3 which will be fed as the input to layer 4\n",
    "layer3_outputs = np.dot(layer2_outputs, np.array(layer3_neuron_weights).T) + biases_of_layer3_neurons\n",
    "\n",
    "# Outputs of Layer 4 which will be fed as the input to layer 5\n",
    "layer4_outputs = np.dot(layer3_outputs, np.array(layer4_neuron_weights).T) + biases_of_layer4_neurons\n",
    "\n",
    "# Outputs of final layer having 3 neurons\n",
    "final_layer5_outputs = np.dot(layer4_outputs, np.array(layer5_neuron_weights).T) + biases_of_layer5_neurons\n",
    "\n",
    "print(\"Output of the final layer having 3 neurons: \", final_layer5_outputs)\n",
    "\n",
    "print(\"\\nBatch wise outputs -->\")\n",
    "for i in range(len(final_layer5_outputs)):\n",
    "  print(f\"Batch {i+1} output: {final_layer5_outputs[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hibiscus_cnn_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
